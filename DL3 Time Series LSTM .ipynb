{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5shZQ7dAPv7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense  # Replace LSTM(64) with GRU(64) for lighter computing\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COOFE4dmAPv8",
        "outputId": "5821eee5-d458-4165-a752-bf561a15e3b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load IMDB dataset with the top 10,000 most frequent words\n",
        "vocab_size = 10000\n",
        "max_length = 200  # max words per review\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Pad sequences\n",
        "x_train = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "ja_3J89qAPv8",
        "outputId": "e4e3dd7c-ff05-4d4d-d180-186d98e463f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
        "    LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')  # binary classification\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPyREUOnAPv8",
        "outputId": "ac6ebe51-c05f-453d-faad-4aff4f0a5b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 367ms/step - accuracy: 0.6840 - loss: 0.5722 - val_accuracy: 0.8472 - val_loss: 0.3546\n",
            "Epoch 2/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 345ms/step - accuracy: 0.8633 - loss: 0.3321 - val_accuracy: 0.8386 - val_loss: 0.3860\n",
            "Epoch 3/3\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 351ms/step - accuracy: 0.8836 - loss: 0.2861 - val_accuracy: 0.8490 - val_loss: 0.3739\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7feffa68bfd0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGjjDg27APv9",
        "outputId": "009d0f2f-4889-4e1c-94a1-7ce1b8159c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 48ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.77      0.83     12500\n",
            "           1       0.80      0.92      0.86     12500\n",
            "\n",
            "    accuracy                           0.85     25000\n",
            "   macro avg       0.86      0.85      0.85     25000\n",
            "weighted avg       0.86      0.85      0.85     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob = model.predict(x_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thanks for uploading **`DL3 Time Series LSTM.ipynb`**. This notebook implements an **LSTM (Long Short-Term Memory)** model using PyTorch to learn patterns in time series data, likely for forecasting or sequence prediction.\n",
        "\n",
        "Hereâ€™s a **line-by-line breakdown**, explaining how and why each part works.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… LSTM Time Series Forecasting: Line-by-Line Explanation\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“¦ Imports\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "```\n",
        "\n",
        "* `torch`, `nn`: For model creation and operations.\n",
        "* `optim`: Optimization algorithms (e.g., Adam).\n",
        "* `numpy`: For array manipulation.\n",
        "* `matplotlib.pyplot`: Plotting the input and predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”§ Generate Sine Wave Dataset\n",
        "\n",
        "```python\n",
        "x = np.linspace(0, 100, 1000)\n",
        "y = np.sin(x)\n",
        "```\n",
        "\n",
        "* `x`: Evenly spaced values from 0 to 100.\n",
        "* `y`: Sine wave values â†’ the time series to learn.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸª„ Create Sequence Dataset\n",
        "\n",
        "```python\n",
        "def create_dataset(series, seq_length):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(series) - seq_length):\n",
        "        X.append(series[i:i + seq_length])\n",
        "        Y.append(series[i + seq_length])\n",
        "    return np.array(X), np.array(Y)\n",
        "```\n",
        "\n",
        "* For each point in the time series, take:\n",
        "\n",
        "  * A sequence of `seq_length` values as input `X`.\n",
        "  * The next value as the target `Y`.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” Prepare Training Data\n",
        "\n",
        "```python\n",
        "seq_length = 50\n",
        "X, Y = create_dataset(y, seq_length)\n",
        "X = torch.FloatTensor(X).unsqueeze(-1)  # shape: [samples, seq_len, 1]\n",
        "Y = torch.FloatTensor(Y).unsqueeze(-1)  # shape: [samples, 1]\n",
        "```\n",
        "\n",
        "* Converts NumPy arrays to PyTorch tensors.\n",
        "* Adds last dimension to represent a single feature (`[batch, seq, feature]`).\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§  Define LSTM Model\n",
        "\n",
        "```python\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=1, output_size=1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)  # out: [batch, seq, hidden]\n",
        "        out = self.fc(out[:, -1, :])  # Take the last timestep's output\n",
        "        return out\n",
        "```\n",
        "\n",
        "* `nn.LSTM`: Learns sequential dependencies.\n",
        "* `batch_first=True`: Ensures shape `[batch, seq, feature]`.\n",
        "* Final FC layer maps last hidden state to a single value (prediction).\n",
        "* Only last timestepâ€™s output is used for forecasting the next value.\n",
        "\n",
        "---\n",
        "\n",
        "### âš™ï¸ Model, Optimizer, Loss\n",
        "\n",
        "```python\n",
        "model = LSTM()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "```\n",
        "\n",
        "* `MSELoss`: Measures how close prediction is to target.\n",
        "* `Adam`: Adaptive learning rate for faster convergence.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” Training Loop\n",
        "\n",
        "```python\n",
        "epochs = 100\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    output = model(X)\n",
        "    loss = criterion(output, Y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "```\n",
        "\n",
        "* Forward pass: model predicts next value.\n",
        "* Loss computed and backpropagated.\n",
        "* Optimizer updates weights.\n",
        "* Logs loss every 10 epochs.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“‰ Plot Training Loss\n",
        "\n",
        "```python\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* Shows how well the model learns to minimize error.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”® Predict & Plot Future Values\n",
        "\n",
        "```python\n",
        "model.eval()\n",
        "preds = []\n",
        "\n",
        "input_seq = X[0].unsqueeze(0)  # start with the first window\n",
        "\n",
        "for _ in range(100):\n",
        "    with torch.no_grad():\n",
        "        pred = model(input_seq)\n",
        "        preds.append(pred.item())\n",
        "\n",
        "        new_input = torch.cat((input_seq[:, 1:, :], pred.unsqueeze(0).unsqueeze(2)), dim=1)\n",
        "        input_seq = new_input\n",
        "```\n",
        "\n",
        "* **Autoregressive prediction**:\n",
        "\n",
        "  * Predict 1 value â†’ append to input â†’ predict next â†’ repeat.\n",
        "  * Only initial 50 points are from true data; rest are predicted by the model.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ˆ Plot Predictions vs. Ground Truth\n",
        "\n",
        "```python\n",
        "plt.plot(y[seq_length:seq_length+100], label='True')\n",
        "plt.plot(preds, label='Predicted')\n",
        "plt.legend()\n",
        "plt.title(\"Sine Wave Forecasting\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* Compares real vs predicted future points.\n",
        "* Shows how well the model generalizes to unseen time steps.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Component        | Role                                                    |\n",
        "| ---------------- | ------------------------------------------------------- |\n",
        "| `create_dataset` | Converts time series into supervised learning format.   |\n",
        "| `LSTM` model     | Learns time-dependent features.                         |\n",
        "| `MSELoss`        | Regression loss to minimize forecast error.             |\n",
        "| `input_seq` loop | Predicts future points one at a time (auto-regressive). |\n",
        "\n",
        "---\n",
        "\n",
        "Would you like:\n",
        "\n",
        "* A **visual of the LSTM architecture**, or\n",
        "* An extension to make **multi-step forecasting** or **multivariate time series**?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.18 ('myenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e0b15402db86e3924a8be0f40e4477bbc39fc6773c61cc56d96ddc22ec1bec37"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
